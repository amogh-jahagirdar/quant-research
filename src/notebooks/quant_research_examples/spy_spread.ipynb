{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T19:34:39.892467Z",
     "iopub.status.busy": "2023-02-23T19:34:39.891968Z",
     "iopub.status.idle": "2023-02-23T19:34:54.058449Z",
     "shell.execute_reply": "2023-02-23T19:34:54.058360Z",
     "shell.execute_reply.started": "2023-02-23 19:34:39.898939+00:00"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-02-23 19:34:39,898.898 configure_magic] Magic cell payload received: {\"conf\": {\"spark.pyspark.python\": \"python3\", \"spark.pyspark.virtualenv.enabled\": \"true\", \"spark.pyspark.virtualenv.type\": \"native\", \"spark.pyspark.virtualenv.bin.path\": \"/usr/bin/virtualenv\", \"spark.sql.execution.arrow.enabled\": \"true\"}, \"proxyUser\": \"assumed-role_fdp_blitvin-Isengard\"}\n",
      "\n",
      "[I 2023-02-23 19:34:39,899.899 configure_magic] Sending request to update kernel. Please wait while the kernel will be refreshed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kernel is successfully refreshed."
     ]
    }
   ],
   "source": [
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "          \"spark.pyspark.python\": \"python3\",\n",
    "          \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "          \"spark.pyspark.virtualenv.type\":\"native\",\n",
    "          \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\",\n",
    "          \"spark.sql.execution.arrow.enabled\":\"true\"\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T19:35:41.522071Z",
     "iopub.status.busy": "2023-02-23T19:35:41.521597Z",
     "iopub.status.idle": "2023-02-23T19:35:44.762587Z",
     "shell.execute_reply": "2023-02-23T19:35:44.761755Z",
     "shell.execute_reply.started": "2023-02-23T19:35:41.521984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tzlocal/unix.py:177: UserWarning: Can not find any timezone configuration, defaulting to UTC.\n",
      "  warnings.warn(\"Can not find any timezone configuration, defaulting to UTC.\")\n",
      "/usr/local/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; mutltipliers will not be applied' +\n"
     ]
    }
   ],
   "source": [
    "import pyEX as p\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vectorbt as vbt\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import datetime\n",
    "#import awswrangler as wr\n",
    "import vectorbt as vbt\n",
    "import pyspark.sql.functions as py_f\n",
    "import pyspark.sql.types as py_t\n",
    "import pyspark.sql.window as py_w\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.timeframe import TimeFrame, TimeFrameUnit\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pyfolio as pf\n",
    "import scipy.stats as stats\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T19:35:44.764759Z",
     "iopub.status.busy": "2023-02-23T19:35:44.764185Z",
     "iopub.status.idle": "2023-02-23T19:35:44.775353Z",
     "shell.execute_reply": "2023-02-23T19:35:44.774671Z",
     "shell.execute_reply.started": "2023-02-23T19:35:44.764730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@py_f.pandas_udf(\"date timestamp, close double, open double, symbol string\", py_f.PandasUDFType.GROUPED_MAP)\n",
    "#@py_f.pandas_udf(\"symbol string\", py_f.PandasUDFType.GROUPED_MAP)\n",
    "#syms=pd.DataFrame([{'symbol':'SPY'}])\n",
    "#get_new_data_df(syms)\n",
    "def get_new_data_df(symbol):\n",
    "    local_sym = str(symbol.values[0][0])\n",
    "    try:\n",
    "        hwm_l = highwatermark_pd_bc.value\n",
    "        columns_to_capture = columns_to_capture_bc.value\n",
    "        iex_base_url = iex_base_url_bc.value\n",
    "        sym_pd = hwm_l.query(f\"symbol=='{local_sym}'\")\n",
    "        if len(sym_pd) > 0:\n",
    "            max_date = sym_pd['max_date'].iloc[0]\n",
    "        else:\n",
    "            max_date = datetime.datetime.now() - datetime.timedelta(days=365 *\n",
    "                                                                    50)\n",
    "        last_days = (datetime.datetime.now() - max_date).days\n",
    "\n",
    "        pyEX_cl = p.Client(api_token=iex_token_bc.value)\n",
    "        final_url = iex_base_url.format(local_sym, iex_token_bc.value,\n",
    "                                        int(last_days))\n",
    "        #'https://cloud.iexapis.com/stable/stock/{}/chart/max?token={}&chartIEXOnly=true&chartLast={}'\n",
    "        print(final_url)\n",
    "        res = requests.get(final_url)\n",
    "        ret_pd = pd.DataFrame(json.loads(res.text))  #[columns_to_capture]\n",
    "        ret_pd = ret_pd.query(f\"date>'{max_date.strftime('%Y-%m-%d')}'\")\n",
    "        ret_pd['date'] = pd.to_datetime(ret_pd['date'])\n",
    "        ret_pd['symbol'] = local_sym\n",
    "        for one_col in ['open', 'high', 'low', 'close']:\n",
    "            ret_pd[f'market{one_col.capitalize()}'] = np.where(\n",
    "                ret_pd[f'market{one_col.capitalize()}'].isnull(),\n",
    "                ret_pd[one_col], ret_pd[f'market{one_col.capitalize()}'])\n",
    "            ret_pd[one_col] = np.where(ret_pd[one_col].isnull(),\n",
    "                                       ret_pd[f'market{one_col.capitalize()}'],\n",
    "                                       ret_pd[one_col])\n",
    "        #return(ret_pd[columns_to_capture].query(f\"date>'{max_date}'\"))\n",
    "    except:\n",
    "        ret_pd = pd.DataFrame([{\n",
    "            'date': datetime.datetime.now() - datetime.timedelta(days=365 * 50),\n",
    "            'minute': None,\n",
    "            'open': None,\n",
    "            'high': None,\n",
    "            'low': None,\n",
    "            'close': None,\n",
    "            'notional': None,\n",
    "            'numberOfTrades': None,\n",
    "            'symbol': local_sym,\n",
    "            'marketOpen': None,\n",
    "            'marketHigh': None,\n",
    "            'marketLow': None,\n",
    "            'marketClose': None,\n",
    "            'marketNotional': None,\n",
    "            'marketNumberOfTrades': None\n",
    "        }])\n",
    "    #return(ret_pd[columns_to_capture],max_date,hwm_l,local_sym,sym_pd)\n",
    "    return (ret_pd[columns_to_capture])\n",
    "    #return(pd.DataFrame([res.text],columns=['symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T19:35:44.776981Z",
     "iopub.status.busy": "2023-02-23T19:35:44.776498Z",
     "iopub.status.idle": "2023-02-23T19:36:07.491562Z",
     "shell.execute_reply": "2023-02-23T19:36:07.490809Z",
     "shell.execute_reply.started": "2023-02-23T19:35:44.776955Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "refresh_data = False\n",
    "timeframe=30\n",
    "\n",
    "class MarketDataGateway():\n",
    "    def __init__(self, tf,isSandbox=False,shard_size=20):\n",
    "        self.shard_size=shard_size\n",
    "        self.fx_etf_symbols = [\n",
    "            'FXA',\n",
    "            'FXY',\n",
    "            'FXE',\n",
    "            'FXB',\n",
    "            'UUP',\n",
    "            'FXC',\n",
    "            'FXF',\n",
    "        ]\n",
    "        self.bitcoin_etf_symbols = [\n",
    "            'BITO', 'BTF', 'XBTF', 'BITS', 'GBTC', 'BITW', 'BLOK', 'BLCN',\n",
    "            'LEGR', 'SPBC', 'BITQ', 'BKCH', 'DAPP', 'BTCFX'\n",
    "        ]\n",
    "        self.bitcoin_equity_proxy_symbols = ['COIN', 'MSTR']\n",
    "        self.crypto_mining_symbols = [\n",
    "            'RIOT', 'CAN', 'HUT', 'HIVE', 'MARA', 'BTCM', 'BTBT', 'BITF'\n",
    "        ]\n",
    "        self.commod_etf_symbols = [\n",
    "            'USO',\n",
    "            'GLD',\n",
    "            'DBA',\n",
    "            'DBB',\n",
    "            'SLV',\n",
    "        ]\n",
    "        self.fi_etf_symbols = [\n",
    "            'IAGG',\n",
    "            'AGG',\n",
    "            'IHY',\n",
    "            'EMLC',\n",
    "            'HYG',\n",
    "        ]\n",
    "        self.equity_share_class_pairs = ['GOOG','GOOGL',\n",
    "'AMC','APE',\n",
    "'BRK.A','BRK.B',\n",
    "'CWEN','CWEN.A',\n",
    "'CRD.A','CRD.B',\n",
    "'FCNCA','FCNCO',\n",
    "'F','F/PC',\n",
    "'GTN','GTN.A',\n",
    "'GEF','GEF.B',\n",
    "'GR3','GB6B',\n",
    "'HLAH','HLAHU',\n",
    "'HEI','HEI.A',\n",
    "'WLY','WLYB',\n",
    "'2F7','2F70',\n",
    "'KELYA','KELYB',\n",
    "'LEN','LEN.B',\n",
    "'LBRDK','LBRDA',\n",
    "'8L8C','8L8',\n",
    "'QRTEA','QRTEB',\n",
    "'LSXMA','LSXMK',\n",
    "'FWONA','FWONK',\n",
    "'BATRA','BATRK',\n",
    "'LTRPA','LTRPB',\n",
    "'MKC','MKC.V',\n",
    "'MKC','MKCV',\n",
    "'MSTR','MSTRD',\n",
    "'TAP','TAP.A',\n",
    "'TPX.A','TPX.B',\n",
    "'MOG.A','MOG.B',\n",
    "'MO7A','MO7R',\n",
    "'NWS','NWSA',\n",
    "'PICC','PICC.U',\n",
    "'RDI','RDIB',\n",
    "'RUSHA','RUSHB',\n",
    "'SENEA','SENEB',\n",
    "'MSGE','MSGS',\n",
    "'T2E','4T0',\n",
    "'FOX','FOXA',\n",
    "'UA','UAA',\n",
    "'UBA','UBP',\n",
    "'0VV','0VVB',\n",
    "'WSO','WSO.B',\n",
    "        ]\n",
    "        self.equity_etf_symbols = [\n",
    "            'AMJ', 'AMLP', 'ARKF', 'ARKG', 'ARKK', 'ARKQ', 'ARKW', 'BOTZ',\n",
    "            'BUG', 'CGW', 'CIBR', 'COPX', 'CRBN', 'DRIV', 'EFV', 'EMLP', 'FBT',\n",
    "            'FDN', 'FIVG', 'FIW', 'FTXG', 'GDX', 'GNR', 'GUNR', 'HACK', 'IAT',\n",
    "            'IBB', 'ICLN', 'IEO', 'IFRA', 'IGE', 'IGF', 'IGM', 'IGV', 'IHF',\n",
    "            'IHI', 'ITB', 'ITZ', 'IWD', 'IWN', 'IWS', 'IYT', 'JETS', 'KBWB',\n",
    "            'KOMP', 'KRE', 'KWEB', 'LCTU', 'LIT', 'MLPA', 'MLPX', 'MOO', 'NFRA',\n",
    "            'OIH', 'PABU', 'PAVE', 'PBW', 'PEJ', 'PHO', 'PICK', 'PPA', 'QCLN',\n",
    "            'REET', 'REMX', 'ROBO', 'SCHH', 'SIL', 'SKYY', 'SMH', 'SOXX',\n",
    "            'SRVR', 'TAN', 'URA', 'URNM', 'VUG', 'XAR', 'XBI', 'XHB', 'XME',\n",
    "            'XOP', 'XSD', 'QQQ', 'EWZ', 'AAXJ', 'VTI', 'EWJ', 'EWA', 'EWC',\n",
    "            'MCHI', 'EWU', 'EWQ', 'EWG', 'FM', 'EIS'\n",
    "        ]\n",
    "        self.sectors = [\n",
    "            'XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE',\n",
    "            'XLK', 'XLU'\n",
    "        ]\n",
    "        self.sp500 = [\n",
    "            \"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"BRK.B\", \"GOOG\", \"NVDA\", \"TSLA\",\n",
    "            \"XOM\", \"UNH\", \"JNJ\", \"JPM\", \"V\", \"META\", \"PG\", \"HD\", \"CVX\", \"MA\",\n",
    "            \"LLY\", \"MRK\", \"ABBV\", \"BAC\", \"PFE\", \"AVGO\", \"KO\", \"PEP\", \"TMO\",\n",
    "            \"COST\", \"WMT\", \"DIS\", \"MCD\", \"CSCO\", \"ABT\", \"WFC\", \"ACN\", \"DHR\",\n",
    "            \"ADBE\", \"CMCSA\", \"VZ\", \"CRM\", \"PM\", \"NKE\", \"NFLX\", \"LIN\", \"TXN\",\n",
    "            \"COP\", \"BMY\", \"NEE\", \"QCOM\", \"RTX\", \"T\", \"HON\", \"CAT\", \"ORCL\",\n",
    "            \"AMGN\", \"UPS\", \"MS\", \"LOW\", \"SBUX\", \"UNP\", \"SPGI\", \"IBM\", \"AMD\",\n",
    "            \"GS\", \"PLD\", \"INTU\", \"BA\", \"ELV\", \"INTC\", \"CVS\", \"DE\", \"BLK\",\n",
    "            \"SCHW\", \"MDT\", \"LMT\", \"GILD\", \"AXP\", \"AMT\", \"C\", \"AMAT\", \"BKNG\",\n",
    "            \"TJX\", \"CB\", \"CI\", \"PYPL\", \"NOW\", \"ADP\", \"GE\", \"ADI\", \"MDLZ\",\n",
    "            \"TMUS\", \"ISRG\", \"MMC\", \"SYK\", \"VRTX\", \"SLB\", \"REGN\", \"MO\", \"EOG\",\n",
    "            \"PGR\", \"DUK\", \"TGT\", \"ZTS\", \"SO\", \"BDX\", \"APD\", \"MU\", \"FISV\",\n",
    "            \"EQIX\", \"AON\", \"LRCX\", \"USB\", \"PNC\", \"BSX\", \"TFC\", \"ITW\", \"ETN\",\n",
    "            \"FCX\", \"MMM\", \"NOC\", \"CCI\", \"CSX\", \"CME\", \"MRNA\", \"EL\", \"MPC\",\n",
    "            \"HUM\", \"ICE\", \"CL\", \"WM\", \"KLAC\", \"PXD\", \"NSC\", \"VLO\", \"HCA\",\n",
    "            \"ATVI\", \"SNPS\", \"MCK\", \"GM\", \"SHW\", \"DG\", \"EMR\", \"F\", \"PSX\", \"D\",\n",
    "            \"GD\", \"SRE\", \"CDNS\", \"MCO\", \"OXY\", \"EW\", \"ORLY\", \"MET\", \"AEP\",\n",
    "            \"NXPI\", \"JCI\", \"PSA\", \"AIG\", \"MAR\", \"APH\", \"A\", \"GIS\", \"ROP\", \"ADM\",\n",
    "            \"CTVA\", \"FDX\", \"ADSK\", \"AZO\", \"COF\", \"FIS\", \"TRV\", \"CMG\", \"NUE\",\n",
    "            \"KMB\", \"HES\", \"CNC\", \"O\", \"IQV\", \"MCHP\", \"DVN\", \"CHTR\", \"MSI\",\n",
    "            \"DOW\", \"NEM\", \"BIIB\", \"MSCI\", \"AFL\", \"SPG\", \"DXCM\", \"ROST\", \"EXC\",\n",
    "            \"TT\", \"PH\", \"AJG\", \"IDXX\", \"LHX\", \"TEL\", \"SYY\", \"HLT\", \"MNST\",\n",
    "            \"PCAR\", \"PRU\", \"WMB\", \"CTAS\", \"XEL\", \"ECL\", \"STZ\", \"AMP\", \"KMI\",\n",
    "            \"HAL\", \"DD\", \"BK\", \"CARR\", \"TDG\", \"YUM\", \"PAYX\", \"WELL\", \"CMI\",\n",
    "            \"ALL\", \"FTNT\", \"MTD\", \"OTIS\", \"EA\", \"CTSH\", \"ED\", \"ILMN\", \"STT\",\n",
    "            \"ALB\", \"RMD\", \"AME\", \"ROK\", \"VICI\", \"WBD\", \"HSY\", \"DFS\", \"DLR\",\n",
    "            \"KEYS\", \"ON\", \"CSGP\", \"DLTR\", \"BKR\", \"KHC\", \"GPN\", \"SBAC\", \"ANET\",\n",
    "            \"OKE\", \"ODFL\", \"DHI\", \"URI\", \"PEG\", \"APTV\", \"PPG\", \"KDP\", \"KR\",\n",
    "            \"WEC\", \"CPRT\", \"AWK\", \"IFF\", \"FAST\", \"ENPH\", \"CEG\", \"VRSK\", \"ES\",\n",
    "            \"GLW\", \"WTW\", \"MTB\", \"CBRE\", \"EBAY\", \"FANG\", \"EFX\", \"WBA\", \"ABC\",\n",
    "            \"HPQ\", \"ZBH\", \"EIX\", \"ULTA\", \"IT\", \"TROW\", \"CDW\", \"PCG\", \"GWW\",\n",
    "            \"FRC\", \"LEN\", \"GEHC\", \"WY\", \"RSG\", \"TSCO\", \"AVB\", \"FITB\", \"HIG\",\n",
    "            \"DAL\", \"LYB\", \"VMC\", \"ARE\", \"FTV\", \"ACGL\", \"GPC\", \"BAX\", \"ANSS\",\n",
    "            \"LH\", \"AEE\", \"FE\", \"IR\", \"ETR\", \"RF\", \"DTE\", \"PPL\", \"RJF\", \"LUV\",\n",
    "            \"PFG\", \"HBAN\", \"MLM\", \"EQR\", \"CFG\", \"PWR\", \"EXR\", \"HPE\", \"HOLX\",\n",
    "            \"DOV\", \"STE\", \"NDAQ\", \"VTR\", \"VRSN\", \"CTRA\", \"CAH\", \"NTRS\", \"WAT\",\n",
    "            \"STLD\", \"WST\", \"ALGN\", \"EPAM\", \"TDY\", \"LVS\", \"CHD\", \"TSN\", \"MPWR\",\n",
    "            \"INVH\", \"MAA\", \"WAB\", \"MKC\", \"CNP\", \"XYL\", \"DRI\", \"BALL\", \"MRO\",\n",
    "            \"CMS\", \"AMCR\", \"IEX\", \"TTWO\", \"FSLR\", \"SWKS\", \"AES\", \"BR\", \"EXPD\",\n",
    "            \"SIVB\", \"KEY\", \"MOH\", \"OMC\", \"PKI\", \"K\", \"EXPE\", \"CAG\", \"ETSY\",\n",
    "            \"BBY\", \"CLX\", \"MOS\", \"TRGP\", \"DGX\", \"SEDG\", \"COO\", \"CINF\", \"SYF\",\n",
    "            \"FMC\", \"CF\", \"ZBRA\", \"TER\", \"SJM\", \"ATO\", \"UAL\", \"INCY\", \"FDS\",\n",
    "            \"JBHT\", \"IRM\", \"NVR\", \"J\", \"PAYC\", \"AVY\", \"FLT\", \"TXT\", \"GRMN\",\n",
    "            \"MTCH\", \"POOL\", \"LKQ\", \"APA\", \"HWM\", \"PEAK\", \"NTAP\", \"TRMB\", \"ESS\",\n",
    "            \"VTRS\", \"PTC\", \"LW\", \"WRB\", \"MKTX\", \"EVRG\", \"WDC\", \"RCL\", \"IPG\",\n",
    "            \"KIM\", \"AKAM\", \"RE\", \"IP\", \"TYL\", \"LNT\", \"STX\", \"MGM\", \"BRO\",\n",
    "            \"JKHY\", \"LDOS\", \"GEN\", \"HST\", \"SNA\", \"PKG\", \"HRL\", \"NDSN\", \"CPT\",\n",
    "            \"CBOE\", \"UDR\", \"DPZ\", \"SWK\", \"TECH\", \"CRL\", \"PHM\", \"CHRW\", \"BF.B\",\n",
    "            \"EQT\", \"CE\", \"HSIC\", \"L\", \"PARA\", \"QRVO\", \"MAS\", \"LYV\", \"TFX\",\n",
    "            \"KMX\", \"CZR\", \"NI\", \"CDAY\", \"TPR\", \"BWA\", \"GL\", \"WYNN\", \"CCL\",\n",
    "            \"EMN\", \"AAL\", \"FOXA\", \"BXP\", \"CPB\", \"JNPR\", \"BIO\", \"BBWI\", \"REG\",\n",
    "            \"ALLE\", \"VFC\", \"UHS\", \"WRK\", \"TAP\", \"CTLT\", \"CMA\", \"RHI\", \"AAP\",\n",
    "            \"FFIV\", \"HII\", \"PNR\", \"WHR\", \"BEN\", \"ROL\", \"PNW\", \"IVZ\", \"FRT\",\n",
    "            \"ZION\", \"XRAY\", \"NWSA\", \"SEE\", \"SBNY\", \"NRG\", \"AOS\", \"OGN\", \"HAS\",\n",
    "            \"GNRC\", \"AIZ\", \"DXC\", \"ALK\", \"NCLH\", \"MHK\", \"NWL\", \"LNC\", \"RL\",\n",
    "            \"LUMN\", \"FOX\", \"DVA\", \"DISH\", \"NWS\"\n",
    "        ]\n",
    "        self.bench_symbol = ['SPY', 'QQQ', 'IVV']\n",
    "        self.all_symbols =self.fx_etf_symbols+\\\n",
    "                            self.bitcoin_etf_symbols+\\\n",
    "                            self.commod_etf_symbols+\\\n",
    "                            self.bitcoin_equity_proxy_symbols+\\\n",
    "                            self.crypto_mining_symbols+\\\n",
    "                            self.fi_etf_symbols+\\\n",
    "                            self.equity_etf_symbols+\\\n",
    "                            self.bench_symbol+\\\n",
    "                            self.sectors+\\\n",
    "                            self.equity_share_class_pairs+\\\n",
    "                            self.sp500\n",
    "        self.all_symbols_df = spark.createDataFrame(\n",
    "            pd.DataFrame(self.all_symbols, columns=['symbol']))\n",
    "        self.all_symbols_df = self.all_symbols_df.withColumn('shard_id',py_f.floor(py_f.row_number().over(py_w.Window.orderBy(\"symbol\"))/self.shard_size))\n",
    "        #all_symbols\n",
    "        self.columns_to_capture = [\n",
    "            'date', 'minute', 'open', 'high', 'low', 'close', 'notional',\n",
    "            'numberOfTrades', 'symbol', 'marketOpen', 'marketHigh', 'marketLow',\n",
    "            'marketClose', 'marketNotional', 'marketNumberOfTrades'\n",
    "        ]\n",
    "        self.type_excl_field_map = {\n",
    "            'date': 'timestamp',\n",
    "            'minute': 'string',\n",
    "            'symbol': 'string'\n",
    "        }\n",
    "        self.pandas_udf_schema =[f\"{i} double\" for i in self.columns_to_capture if (i not in self.type_excl_field_map.keys()) ] +\\\n",
    "                                    [f\"{i[0]} {i[1]}\" for i in self.type_excl_field_map.items()]\n",
    "\n",
    "        self.data_folder = 's3://fsidatalake/intraday_market_data/'\n",
    "        self.parquet_file_out = f\"{self.data_folder}OHLC_{tf}m.parquet\"\n",
    "        if isSandbox:\n",
    "            self.iex_token = 'Tpk_02dcd2036e7641b880dd4cbb01fa9c67'\n",
    "            self.iex_ver = 'sandbox'\n",
    "        else:\n",
    "            #self.iex_token ='pk_2e94555e43da4135a6032433c6b18fa5' pk_79d147436c1349f3abbec37591323e52\n",
    "            self.iex_token = 'pk_79d147436c1349f3abbec37591323e52'\n",
    "            self.iex_ver = 'stable'\n",
    "        self.iex_base_url = 'https://cloud.iexapis.com/' + self.iex_ver + '/stock/{}/chart/1mm?token={}&chartIEXOnly=true'\n",
    "\n",
    "    def set_highwatermarks(self):\n",
    "        try:\n",
    "            self.old_df = spark.read.parquet(self.parquet_file_out)\n",
    "        except:\n",
    "            #self.old_df = spark.createDataFrame(pd.DataFrame([{'symbol':'----','date':datetime.datetime.now()-datetime.timedelta(days=365*50)}]))\n",
    "            self.old_pd = self.all_symbols_df.toPandas()\n",
    "            self.old_pd['date'] = datetime.datetime.now() - datetime.timedelta(\n",
    "                days=365 * 50)\n",
    "            self.old_df = spark.createDataFrame(self.old_pd)\n",
    "        self.highwatermark_pd = self.old_df.groupby('symbol').agg(\n",
    "            py_f.max(\"date\").alias(\"max_date\"),\n",
    "            py_f.min(\"date\").alias(\"min_date\"),\n",
    "            (py_f.max(\"date\") -\n",
    "             py_f.min(\"date\")).alias(\"date_length\")).toPandas()\n",
    "\n",
    "    def set_new_symbol_df(self):\n",
    "        self.new_sym_df=self.all_symbols_df.groupby(\"symbol\")\\\n",
    "                        .applyInPandas(get_new_data_df, schema= ','.join(self.pandas_udf_schema))\\\n",
    "                        .where('close is not null')\n",
    "\n",
    "    def write_new_symbol_df(self):\n",
    "        self.write_stats = self.new_sym_df.groupby('symbol').agg(\n",
    "            py_f.count('symbol').alias('data_count'))\n",
    "        self.new_sym_df.write\\\n",
    "            .option(\"header\",True)\\\n",
    "            .partitionBy('symbol')\\\n",
    "            .mode(\"append\")\\\n",
    "            .parquet(self.parquet_file_out)\n",
    "\n",
    "    def set_sp500_constituents(self):\n",
    "        pass\n",
    "\n",
    "    def rewrite_if_dups(self):\n",
    "        self.old_df_after_write = spark.read.parquet(self.parquet_file_out)\n",
    "        self.dup_df = self.old_df_after_write.distinct().groupby(\n",
    "            'date', 'symbol').count()\n",
    "        dup_count = self.dup_df.where('count>1').count()\n",
    "        if dup_count > 0:\n",
    "            print(f\"found:{dup_count} dups; sample:{self.dup_df.show()}\")\n",
    "            self.old_df_after_write.groupby('date','symbol').agg(py_f.mean('close').alias('close'),py_f.mean('open').alias('open'))\\\n",
    "            .write\\\n",
    "            .option(\"header\",True)\\\n",
    "            .partitionBy('symbol')\\\n",
    "            .mode(\"overwrite\")\\\n",
    "            .parquet(self.parquet_file_out.replace('.parquet','_temp.parquet'))\n",
    "        else:\n",
    "            print(f\"no dups\")\n",
    "\n",
    "\n",
    "mdg = MarketDataGateway(timeframe)\n",
    "mdg.set_highwatermarks()\n",
    "# set bc vars\n",
    "highwatermark_pd_bc = sc.broadcast(mdg.highwatermark_pd)\n",
    "columns_to_capture_bc = sc.broadcast(mdg.columns_to_capture)\n",
    "iex_token_bc = sc.broadcast(mdg.iex_token)\n",
    "iex_base_url_bc = sc.broadcast(mdg.iex_base_url)\n",
    "# set bc vars\n",
    "if refresh_data:\n",
    "    mdg.set_new_symbol_df()\n",
    "    mdg.write_new_symbol_df()\n",
    "    print(mdg.write_stats.toPandas().sort_values(['symbol']))\n",
    "#mdg.rewrite_if_dups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T19:36:07.493907Z",
     "iopub.status.busy": "2023-02-23T19:36:07.493402Z",
     "iopub.status.idle": "2023-02-23T19:36:07.509972Z",
     "shell.execute_reply": "2023-02-23T19:36:07.509237Z",
     "shell.execute_reply.started": "2023-02-23T19:36:07.493880Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeframe=30\n",
    "def get_emtpy_df(l_exc,symbols):\n",
    "        return(pd.DataFrame([{\n",
    "            'symbol':f'\",\".join(symbols):{l_exc}',\n",
    "            'timestamp_utc':None,\n",
    "            'open':None,\n",
    "            'high':None,\n",
    "            'low':None,\n",
    "            'close':None,\n",
    "            'volume':None,\n",
    "            'trade_count':None,\n",
    "            'vwap':None,\n",
    "            'date':None,\n",
    "            'minute':None,\n",
    "        }]))\n",
    "def get_alpaca_data(start_date,end_date,symbols,tf):\n",
    "        ALPACA_API_KEY_ID = 'AK8MWGDK1GMSP91W1SGM'\n",
    "        ALPACA_API_SECRET_KEY = 'oM5h4WWGfuKrctHWdCmtpwLcOuoV5TLemJ5ImavI'\n",
    "        data_client = StockHistoricalDataClient(ALPACA_API_KEY_ID,\n",
    "                                                ALPACA_API_SECRET_KEY)\n",
    "        timeframe_30_min = TimeFrame(tf, TimeFrameUnit.Minute)\n",
    "\n",
    "        request_parameters = StockBarsRequest(\n",
    "            symbol_or_symbols=symbols,\n",
    "            timeframe=timeframe_30_min,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "        )\n",
    "\n",
    "        # Fetch data and convert to dataframe\n",
    "        min_30_bars = data_client.get_stock_bars(\n",
    "            request_parameters).df.reset_index()\n",
    "        min_30_bars['date'] = min_30_bars.timestamp.dt.date\n",
    "        min_30_bars['minute'] = (min_30_bars.timestamp.dt.hour.astype(str).str.pad(\n",
    "            2, fillchar='0')) + \":\" + (min_30_bars.timestamp.dt.minute.astype(\n",
    "                str).str.pad(2, fillchar='0'))\n",
    "        min_30_bars=min_30_bars.rename(columns={'timestamp':'timestamp_utc'})\n",
    "        return(min_30_bars)\n",
    "def get_new_data_df_alpaca(symbol,tf):\n",
    "    ret_columns= ['symbol' ,'timestamp_utc' ,'open' ,'high'  \\\n",
    "    ,'low' ,'close' ,'volume' ,'trade_count' ,'vwap' ,'date' ,'minute' ]\n",
    "    try:\n",
    "        start_date = \"2000-01-02\"\n",
    "        end_date = \"2023-02-06\"\n",
    "        if type(symbol) == pd.core.frame.DataFrame:\n",
    "            symbols = [i for i in symbol.symbol.values]\n",
    "        else:\n",
    "            local_syms = str(symbol.values[0][0])\n",
    "            symbols = [local_syms]\n",
    "\n",
    "\n",
    "        # Set parameters\n",
    "\n",
    "        start_date = pd.to_datetime(start_date).tz_localize('America/New_York')\n",
    "        end_date = pd.to_datetime(end_date).tz_localize('America/New_York')\n",
    "\n",
    "        min_30_bars=get_alpaca_data(start_date,end_date,symbols,tf)\n",
    "    except Exception as l_exc:\n",
    "        print(f'exception{str(l_exc)} for {\",\".join(symbols)}')\n",
    "        if l_exc.code==42210000:\n",
    "            try:\n",
    "                rejected_symbols = [i.replace(' ','') for i in json.loads(l_exc.args[0])['message'].split(':')[1].split(',')]\n",
    "                clean_symbols = [i for i in symbols if i not in rejected_symbols]\n",
    "                min_30_bars=get_alpaca_data(start_date,end_date,clean_symbols)\n",
    "            except Exception as L_exc_1:\n",
    "                min_30_bars=get_empty_df()\n",
    "        else:\n",
    "            min_30_bars=get_emtpy_df(l_exc,symbols)\n",
    "    return (min_30_bars)\n",
    "\n",
    "\n",
    "sym_list = [\n",
    "    'XLC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK',\n",
    "    'XLU', 'SPY', 'QQQ', 'VTI', 'VTV', 'BND', 'AGG', 'VUG', 'VIG', 'IJR', 'IJH',\n",
    "    'IEMG', 'IWF', 'IWD', 'GLD', 'IWM', 'VYM', 'VXUS', 'VO', 'EFA', 'SCHD',\n",
    "    'ARKK'\n",
    "]\n",
    "if False:\n",
    "    etf_pd = get_new_data_df_alpaca(sym_list,timeframe)\n",
    "if False:\n",
    "    #syms=pd.DataFrame([{'symbol':'XLC'}])\n",
    "    #etf_pd = get_new_data_df_alpaca(syms)\n",
    "    panda_udf_schema = \"symbol string,timestamp_utc timestamp,open double,high double \\\n",
    "    ,low double,close double,volume double,trade_count double,vwap double,date date,minute string\"\n",
    "    \n",
    "    new_sym_df=mdg.all_symbols_df.where(py_f.col('symbol').isin(['ARKK','SPY','QQQ'])).distinct().groupby(\"shard_id\")\\\n",
    "                            .applyInPandas(lambda x: get_new_data_df_alpaca(x,timeframe), schema=panda_udf_schema )\\\n",
    "                            #.where('close is not null')\n",
    "    #print(new_sym_df.count())\n",
    "    new_sym_df.write\\\n",
    "                .option(\"header\",True)\\\n",
    "                .partitionBy('symbol')\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .parquet(mdg.parquet_file_out)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T22:37:53.143567Z",
     "iopub.status.busy": "2023-02-23T22:37:53.143056Z",
     "iopub.status.idle": "2023-02-23T22:38:20.909995Z",
     "shell.execute_reply": "2023-02-23T22:38:20.909223Z",
     "shell.execute_reply.started": "2023-02-23T22:37:53.143537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://fsidatalake/intraday_market_data/OHLC_30m.parquet\n",
      "+------+----------+----------+----------+---------+-----------+------------+---------+---------+--------+----------+-----------+---------------------------+\n",
      "|symbol|date      |open_first|high_first|low_first|close_first|minute_first|open_last|high_last|low_last|close_last|minute_last|daily_pct_change_open_close|\n",
      "+------+----------+----------+----------+---------+-----------+------------+---------+---------+--------+----------+-----------+---------------------------+\n",
      "|A     |2016-03-11|38.43     |38.68     |38.32    |38.63      |14:30       |39.18    |39.272   |39.13   |39.215    |20:30      |0.020426749934946642       |\n",
      "|A     |2016-05-13|42.77     |42.85     |42.56    |42.59      |14:30       |42.65    |42.65    |42.65   |42.65     |20:30      |-0.002805704933364628      |\n",
      "|A     |2016-11-22|44.94     |45.16     |44.735   |44.805     |14:30       |44.4     |44.49    |44.385  |44.465    |20:30      |-0.01056964842011554       |\n",
      "+------+----------+----------+----------+---------+-----------+------------+---------+---------+--------+----------+-----------+---------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+----+----------+----------+---------+-----------+------------+---------+---------+--------+----------+-----------+---------------------------+\n",
      "|symbol|date|open_first|high_first|low_first|close_first|minute_first|open_last|high_last|low_last|close_last|minute_last|daily_pct_change_open_close|\n",
      "+------+----+----------+----------+---------+-----------+------------+---------+---------+--------+----------+-----------+---------------------------+\n",
      "+------+----+----------+----------+---------+-----------+------------+---------+---------+--------+----------+-----------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study_config = {'first_bar':'14:30',\n",
    "                'last_bar':'20:30',\n",
    "                'bench_symbol_market':'SPY',\n",
    "                'bench_symbol_local':'QQQ'\n",
    "               }\n",
    "###\n",
    "if True:\n",
    "    print(mdg.parquet_file_out)\n",
    "    study_df =spark.read.parquet(mdg.parquet_file_out) #spark.read.parquet('s3://fsidatalake/intraday_market_data/OHLC_30m.parquet')#mdg.parquet_file_out)\n",
    "else:\n",
    "    sym_sample = spark.read.parquet(etf_parquet_file)\n",
    "study_df.select('symbol').distinct().count()\n",
    "#########################\n",
    "window_part=py_w.Window.partitionBy('symbol','date').orderBy('timestamp_utc')\n",
    "window_cum=window_part.rowsBetween(py_w.Window.unboundedPreceding, 0)\n",
    "window_prev=window_part\n",
    "###\n",
    "#mul_udf = F.udf(lambda x: reduce(mul, x), types.IntegerType())\n",
    "###\n",
    "study_df = study_df.where(f'minute>=\"{study_config.get(\"first_bar\")}\" and minute<=\"{study_config.get(\"last_bar\")}\" ')\n",
    "\n",
    "cols=['date','open','high','low','close','symbol','minute']\n",
    "final_bar_per_day = study_df.groupBy('date').agg(py_f.max('timestamp_utc').alias('final_day_bar'))\n",
    "first_bar_per_day = study_df.groupBy('date').agg(py_f.min('timestamp_utc').alias('first_day_bar'))\n",
    "study_df_last=study_df.join(final_bar_per_day,on='date').where(\"final_day_bar==timestamp_utc \").select(*cols).\\\n",
    "                    withColumnRenamed('open','open_last').\\\n",
    "                    withColumnRenamed('high','high_last').\\\n",
    "                    withColumnRenamed('low','low_last').\\\n",
    "                    withColumnRenamed('close','close_last').\\\n",
    "                    withColumnRenamed('minute','minute_last')\n",
    "study_df_first=study_df.join(first_bar_per_day,on='date').where(\"first_day_bar==timestamp_utc \").select(*cols).\\\n",
    "                    withColumnRenamed('open','open_first').\\\n",
    "                    withColumnRenamed('high','high_first').\\\n",
    "                    withColumnRenamed('low','low_first').\\\n",
    "                    withColumnRenamed('close','close_first').\\\n",
    "                    withColumnRenamed('minute','minute_first')\n",
    "study_df_first_last=study_df_first.join(study_df_last,on=['symbol','date'])\n",
    "study_df_first_last=study_df_first_last.withColumn('daily_pct_change_open_close',(py_f.col('close_last')/py_f.col('open_first'))-1)\n",
    "study_df_first_last.show(3,truncate=False)\n",
    "study_df_first_last.where(\"minute_last!='20:30' or minute_first!='14:30'\").orderBy('date').show(150)\n",
    "study_pd=study_df_first_last.toPandas().set_index('date').sort_index()\n",
    "study_pd['daily_pct_change']=study_pd.groupby('symbol')['close_last'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T22:40:34.313438Z",
     "iopub.status.busy": "2023-02-23T22:40:34.313007Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_pd.reset_index().sort_values(['symbol','date']).head(100).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_pd_no_bench = study_pd.query(f\"symbol!='{study_config.get('bench_symbol_market')}' and symbol!='{study_config.get('bench_symbol_local')}'\")\\\n",
    "                    .set_index('date').sort_index()\n",
    "study_pd_bench_market = study_pd.query(f\"symbol=='{study_config.get('bench_symbol_market')}'\")\\\n",
    "                    .set_index('date').sort_index()\n",
    "study_pd_bench_local = study_pd.query(f\"symbol=='{study_config.get('bench_symbol_local')}'\")\\\n",
    "                    .set_index('date').sort_index()\n",
    "final_cols = ['symbol','date','daily_pct_change','close_last']\n",
    "study_pd_final=study_pd_no_bench.join(study_pd_bench_market[['symbol','daily_pct_change','close_last']],rsuffix='_bench_market').join(study_pd_bench_local[['symbol','daily_pct_change','close_last']],rsuffix='_bench_local')\n",
    "study_pd_final['spread_symbol_vs_market']=study_pd_final['daily_pct_change']-study_pd_final['daily_pct_change_bench_market']\n",
    "study_pd_final['spread_local_vs_market']=study_pd_final['daily_pct_change_bench_local']-study_pd_final['daily_pct_change_bench_market']\n",
    "study_pd_final=study_pd_final.groupby('symbol').apply(lambda x: x.sort_index().fillna(method='ffill'))\n",
    "study_pd_final=study_pd_final.drop(columns=['symbol']).reset_index().set_index('date')\n",
    "study_DF_final=spark.createDataFrame(study_pd_final.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_DF_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "@jit\n",
    "def one_day_np(l_df):\n",
    "    if False:\n",
    "        def get_rmse(y,y_pred):\n",
    "            return(np.sqrt((np.sum((y_pred-y)**2))/len(y)))\n",
    "        def get_r2(y,y_pred):\n",
    "            y_ypred_corr = np.corrcoef(y,y_pred)\n",
    "            corr=y_ypred_corr[0,1]\n",
    "            return(corr**2)\n",
    "\n",
    "        is_last_raw=l_df[:,4]\n",
    "        is_last=is_last_raw[len(is_last_raw)-1]\n",
    "        if len(l_df)>1:\n",
    "            x=l_df[:,0]\n",
    "            y=l_df[:,1]\n",
    "            b1=np.corrcoef(x,y)[0][1]*(np.std(y)/np.std(x))\n",
    "            c=np.mean(y)-b1*np.mean(x)\n",
    "            y_pred= c+b1*x\n",
    "            rmse=get_rmse(y,y_pred)\n",
    "            r2=get_r2(y,y_pred)\n",
    "            \n",
    "            ptiles=np.percentile(y_pred-y, [1,5,10,25,75,90,95,99]) \n",
    "            p1=ptiles[0]\n",
    "            p5=ptiles[1]\n",
    "            p10=ptiles[2]\n",
    "            p25=ptiles[3]\n",
    "            p75=ptiles[4]\n",
    "            p90=ptiles[5]\n",
    "            p95=ptiles[6]\n",
    "            p99=ptiles[7]\n",
    "        else:\n",
    "            c,b1,rmse,r2,is_last,p1,p5,p10,p25,p75,p90,p95,p99=0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "        ret_val=[c,b1,rmse,r2,is_last,p1,p5,p10,p25,p75,p90,p95,p99]\n",
    "    else:\n",
    "        ret_val=[1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "    return(ret_val)\n",
    "\n",
    "def one_day_ols(l_df):\n",
    "    from statsmodels.tools.eval_measures import rmse\n",
    "    ret_dict={}\n",
    "    try:\n",
    "        Y=np.array(l_df['spread_local_vs_market'].values)\n",
    "        X=np.array(l_df['spread_symbol_vs_market'].values)\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(Y,X)\n",
    "        results = model.fit()\n",
    "        ret_dict['symbol'] = l_df.symbol.drop_duplicates().values[0]\n",
    "        ret_dict['r2'] = results.rsquared\n",
    "        ret_dict['pval_0'] = (results.pvalues[0])\n",
    "        ret_dict['pval_1'] = (results.pvalues[1])\n",
    "        ret_dict['const']=(results.params[0])\n",
    "        ret_dict[f'coeff']=(results.params[1])\n",
    "        ypred = results.predict(X)\n",
    "        rmse = rmse(Y, ypred)\n",
    "        ret_dict['rmse']=rmse\n",
    "    except:\n",
    "        ret_dict['symbol'] = l_df.symbol.drop_duplicates().values[0]\n",
    "        ret_dict['r2']=0.0\n",
    "        ret_dict['pval_0']=0.0\n",
    "        ret_dict['pval_1']=0.0\n",
    "        ret_dict['const']=0.0\n",
    "        ret_dict['coeff']=0.0\n",
    "        ret_dict['rmse']=0.0\n",
    "    return(pd.DataFrame([ret_dict]))\n",
    "res=(one_day_ols(study_pd_final))\n",
    "print(res)\n",
    "@jit\n",
    "def test(l_df):\n",
    "    #print((l_df))\n",
    "    return([0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "panda_udf_schema='symbol string,r2 double,pval_0 double,pval_1 double,const double,coeff double,rmse double'\n",
    "regr_res_pd = study_DF_final.groupby('symbol').applyInPandas(one_day_ols,schema=panda_udf_schema  ).toPandas().set_index('symbol').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(regr_res_pd.query(f'r2>0.40 and pval_1<0.01').sort_index())\n",
    "arkk_like_symbols = regr_res_pd.query(f'r2>0.40 and pval_1<0.01').index.values\n",
    "arkk_like_symbols=list(list(arkk_like_symbols)+[study_config.get(\"bench_symbol_market\"),study_config.get(\"bench_symbol_local\")])\n",
    "arkk_like_pd =study_DF_final.filter(py_f.col('symbol').isin(arkk_like_symbols)).toPandas()\n",
    "arkk_like_pd=arkk_like_pd.set_index('symbol').join(regr_res_pd)\n",
    "arkk_like_pd['coeff_sign']=(arkk_like_pd['coeff']>0)*1 + (arkk_like_pd['coeff']<0)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arkk_like_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arkk_like_pd['is_aligned']=(((arkk_like_pd['daily_pct_change_bench_local']>arkk_like_pd['daily_pct_change_bench_market'])&((arkk_like_pd['daily_pct_change']*arkk_like_pd['coeff_sign'])>=arkk_like_pd['daily_pct_change_bench_market'])) + \\\n",
    "                             ((arkk_like_pd['daily_pct_change_bench_local']<arkk_like_pd['daily_pct_change_bench_market'])&((arkk_like_pd['daily_pct_change']*arkk_like_pd['coeff_sign'])<arkk_like_pd['daily_pct_change_bench_market'])))*(1)\n",
    "align_stats=arkk_like_pd.groupby(['symbol','is_aligned']).count()[['open_first']].reset_index().pivot_table(values='open_first',columns='is_aligned',index='symbol')\n",
    "align_stats['total']=align_stats[0]+align_stats[1]\n",
    "align_stats['aligned']=round(100*(align_stats[1]/align_stats['total']),2)\n",
    "align_stats['not_aligned']=round(100*(align_stats[0]/align_stats['total']),2)\n",
    "align_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(arkk_like_pd.query(\"symbol=='IWD'\")[['daily_pct_change','daily_pct_change_bench_market','daily_pct_change_bench_local']]*100).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "        spark.createDataFrame(arkk_like_pd.reset_index()).coalesce(1).repartition(1).write\\\n",
    "                        .option(\"header\",True)\\\n",
    "                        .mode(\"overwrite\")\\\n",
    "                        .parquet('s3://fsidatalake/intraday_market_data/align_study_md.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Kubernetes)",
   "language": "python",
   "name": "spark_python_kubernetes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
