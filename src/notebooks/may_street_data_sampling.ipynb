{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T17:42:49.083231Z",
     "iopub.status.busy": "2022-10-18T17:42:49.082534Z",
     "iopub.status.idle": "2022-10-18T17:42:49.410615Z",
     "shell.execute_reply": "2022-10-18T17:42:49.409094Z",
     "shell.execute_reply.started": "2022-10-18T17:42:49.083190Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv', 'spark.sql.files.ignoreCorruptFiles': 'true', 'spark.dynamicAllocation.executorIdleTimeout': '18000', 'spark.driver.memory': '24g', 'spark.executor.memory': '24g', 'spark.driver.cores': '5', 'spark.driver.maxResultSize': '5g'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "        \"spark.pyspark.python\": \"python3\"\n",
    "    ,\"spark.pyspark.virtualenv.enabled\": \"true\"\n",
    "    ,\"spark.pyspark.virtualenv.type\":\"native\"\n",
    "    ,\"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "    ,\"spark.sql.files.ignoreCorruptFiles\":\"true\"\n",
    "    ,\"spark.dynamicAllocation.executorIdleTimeout\":\"18000\"\n",
    "    ,\"spark.driver.memory\":\"24g\",\"spark.executor.memory\":\"24g\"\n",
    "    ,\"spark.driver.cores\":\"5\"\n",
    "    ,\"spark.driver.maxResultSize\":\"5g\"\n",
    "         }\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/basics-of-apache-spark-configuration-settings-ca4faff40d45\n",
    "https://luminousmen.com/post/spark-tips-partition-tuning\n",
    "https://sparkbyexamples.com/pyspark/pyspark-repartition-vs-partitionby/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T17:42:52.085451Z",
     "iopub.status.busy": "2022-10-18T17:42:52.085101Z",
     "iopub.status.idle": "2022-10-18T17:44:14.302088Z",
     "shell.execute_reply": "2022-10-18T17:44:14.300994Z",
     "shell.execute_reply.started": "2022-10-18T17:42:52.085422Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967830eed4ca4822b0a3d8aff7d174ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1666113837887_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-2-48.us-east-2.compute.internal:20888/proxy/application_1666113837887_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-12-189.us-east-2.compute.internal:8042/node/containerlogs/container_1666113837887_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp==3.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/fe/80c594d62a7ff07730fd2cfc3a058498087436d8c938243e0610d1928f0e/aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1MB)\n",
      "Collecting typing-extensions>=3.7.4; python_version < \"3.8\" (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/8e/f1a0a5a76cfef77e1eb6004cb49e5f8d72634da638420b9ea492ce8305e8/typing_extensions-4.4.0-py3-none-any.whl\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/87/fe94898f2d44a93a35d5aa74671ed28094d80753a1113d68b799fab6dc22/aiosignal-1.2.0-py3-none-any.whl\n",
      "Collecting charset-normalizer<3.0,>=2.0 (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/51/a507c856293ab05cdc1db77ff4bc1268ddd39f29e7dc4919aa497f0adbec/charset_normalizer-2.1.1-py3-none-any.whl\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/04/255c68974ec47fa754564c4abba8f61f9ed68b869bbbb854198d6259c4f7/yarl-1.8.1.tar.gz (172kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/a7/71c253cdb8a1528802bac7503bf82fe674367e4055b09c28846fdfa4ab90/multidict-6.0.2.tar.gz (50kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/bc/d817287d1aa01878af07c19505fafd1165cd6a119e9d0821ca1d1c20312d/attrs-22.1.0-py2.py3-none-any.whl (58kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/b2/cf7e86583f03fafc93c4103f9a03aaf729dcf4dca9cd3012256a48b766ad/frozenlist-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148kB)\n",
      "Collecting asynctest==0.13.0; python_version < \"3.8\" (from aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/b6/8d17e169d577ca7678b11cd0d3ceebb0a6089a7f4a2de4b945fe4b1c86db/asynctest-0.13.0-py3-none-any.whl\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.0->aiohttp==3.8.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl (61kB)\n",
      "Building wheels for collected packages: yarl, multidict\n",
      "  Running setup.py bdist_wheel for yarl: started\n",
      "  Running setup.py bdist_wheel for yarl: finished with status 'done'\n",
      "  Stored in directory: /var/lib/livy/.cache/pip/wheels/33/f3/b3/19157d9ed9a5cb7e3c701ca6f99bd086ab162e4ef57729c008\n",
      "  Running setup.py bdist_wheel for multidict: started\n",
      "  Running setup.py bdist_wheel for multidict: finished with status 'done'\n",
      "  Stored in directory: /var/lib/livy/.cache/pip/wheels/e7/67/fd/4e3843a89ae0e233d79452f8f04e45814f350173a99f5addc9\n",
      "Successfully built yarl multidict\n",
      "Installing collected packages: typing-extensions, frozenlist, aiosignal, charset-normalizer, multidict, idna, yarl, attrs, async-timeout, asynctest, aiohttp\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 attrs-22.1.0 charset-normalizer-2.1.1 frozenlist-1.3.1 idna-3.4 multidict-6.0.2 typing-extensions-4.4.0 yarl-1.8.1\n",
      "\n",
      "Collecting pandas==1.1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/70/e8eee0cbddf926bf51958c7d6a86bc69167c300fa2ba8e592330a2377d1b/pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5MB)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib64/python3.7/site-packages (from pandas==1.1.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas==1.1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl (247kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-1.1.5 python-dateutil-2.8.2\n",
      "\n",
      "Collecting pyarrow==0.14.1\n",
      "  Downloading https://files.pythonhosted.org/packages/48/ab/8691c96c81e8a8493e26314a99efcdde97b9ed9c1e5cd705e97d15e79502/pyarrow-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (58.2MB)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/lib64/python3.7/site-packages (from pyarrow==0.14.1)\n",
      "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.7/site-packages (from pyarrow==0.14.1)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-0.14.1\n",
      "\n",
      "Collecting s3fs\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/6a/d2b077d0d03e02077d697f3ec03012f500cea49c4e703d59d551018cf9ee/s3fs-2022.8.2-py3-none-any.whl\n",
      "Collecting fsspec==2022.8.2 (from s3fs)\n",
      "  Downloading https://files.pythonhosted.org/packages/82/f3/30f7925f22f623ebac35b40d48151578ef7303d897764e1d95323727611b/fsspec-2022.8.2-py3-none-any.whl (140kB)\n",
      "Collecting aiobotocore~=2.4.0 (from s3fs)\n",
      "  Downloading https://files.pythonhosted.org/packages/75/f3/2fccfdd0a6ade32246547404132d980ffb27461d339ab4b1e3802a152d69/aiobotocore-2.4.0-py3-none-any.whl (65kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from s3fs)\n",
      "Collecting aioitertools>=0.5.1 (from aiobotocore~=2.4.0->s3fs)\n",
      "  Downloading https://files.pythonhosted.org/packages/45/66/d1a9fd8e6ff88f2157cb145dd054defb0fd7fe2507fe5a01347e7c690eab/aioitertools-0.11.0-py3-none-any.whl\n",
      "Collecting botocore<1.27.60,>=1.27.59 (from aiobotocore~=2.4.0->s3fs)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/70/d09a704da82119d64848826dbbd5a8c18e5b57ca6aca0061634d6418c01a/botocore-1.27.59-py3-none-any.whl (9.1MB)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /usr/local/lib64/python3.7/site-packages (from aiobotocore~=2.4.0->s3fs)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: asynctest==0.13.0; python_version < \"3.8\" in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs)\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/de/5be2e3eed8426f871b170663333a0f627fc2924cc386cd41be065e7ea870/urllib3-1.26.12-py2.py3-none-any.whl (140kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs)\n",
      "Requirement already satisfied: idna>=2.0 in /mnt/tmp/1666114994690-0/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs)\n",
      "Installing collected packages: fsspec, aioitertools, urllib3, botocore, aiobotocore, s3fs\n",
      "Successfully installed aiobotocore-2.4.0 aioitertools-0.11.0 botocore-1.27.59 fsspec-2022.8.2 s3fs-2022.8.2 urllib3-1.26.12"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sc.install_pypi_package(\"aiohttp==3.8.1\")\n",
    "except: \n",
    "    print(f'aiohttp is installed')\n",
    "try:\n",
    "    import pandas as pd\n",
    "except: \n",
    "    sc.install_pypi_package(\"pandas==1.1.5\")\n",
    "    import pandas as pd\n",
    "try:\n",
    "    import pyarrow\n",
    "except: \n",
    "    sc.install_pypi_package(\"pyarrow==0.14.1\")\n",
    "    import pyarrow \n",
    "try:\n",
    "    import s3fs\n",
    "except: \n",
    "    sc.install_pypi_package(\"s3fs\")\n",
    "    import s3fs \n",
    "try:\n",
    "    import fsspec\n",
    "except: \n",
    "    sc.install_pypi_package(\"fsspec\")\n",
    "    import fsspec \n",
    "if False:\n",
    "    try:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "    except: \n",
    "        sc.install_pypi_package(\"matplotlib\")\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as py_f\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T17:44:14.304153Z",
     "iopub.status.busy": "2022-10-18T17:44:14.303794Z",
     "iopub.status.idle": "2022-10-18T17:44:14.574240Z",
     "shell.execute_reply": "2022-10-18T17:44:14.573111Z",
     "shell.execute_reply.started": "2022-10-18T17:44:14.304111Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239714bc3686491893e7def6e5141219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.6-amzn-0 \n",
      "\n",
      "\n",
      "('spark.driver.memory', '24g')\n",
      "('spark.eventLog.enabled', 'true')\n",
      "('spark.yarn.executor.memoryOverheadFactor', '0.1875')\n",
      "('spark.executorEnv.PYTHONPATH', '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip')\n",
      "('spark.driver.extraLibraryPath', '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native')\n",
      "('spark.sql.parquet.output.committer.class', 'com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter')\n",
      "('spark.driver.cores', '5')\n",
      "('spark.blacklist.decommissioning.timeout', '1h')\n",
      "('spark.yarn.appMasterEnv.SPARK_PUBLIC_DNS', '$(hostname -f)')\n",
      "('spark.sql.emr.internal.extensions', 'com.amazonaws.emr.spark.EmrSparkSessionExtensions')\n",
      "('spark.yarn.secondary.jars', 'livy-api-0.7.0-incubating.jar,livy-rsc-0.7.0-incubating.jar,livy-thriftserver-session-0.7.0-incubating.jar,netty-all-4.1.17.Final.jar,commons-codec-1.9.jar,livy-core_2.11-0.7.0-incubating.jar,livy-repl_2.11-0.7.0-incubating.jar')\n",
      "('spark.eventLog.dir', 'hdfs:///var/log/spark/apps')\n",
      "('spark.jars', 'file:/usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:/usr/lib/livy/repl_2.11-jars/commons-codec-1.9.jar,file:/usr/lib/livy/repl_2.11-jars/livy-core_2.11-0.7.0-incubating.jar,file:/usr/lib/livy/repl_2.11-jars/livy-repl_2.11-0.7.0-incubating.jar')\n",
      "('spark.sql.warehouse.dir', 'hdfs:///user/spark/warehouse')\n",
      "('spark.history.fs.logDirectory', 'hdfs:///var/log/spark/apps')\n",
      "('spark.ui.filters', 'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter')\n",
      "('spark.pyspark.python', 'python3')\n",
      "('spark.executor.memory', '24g')\n",
      "('spark.repl.class.outputDir', '/tmp/spark1312759907246128684')\n",
      "('spark.pyspark.virtualenv.packages', 'aiohttp==3.8.1,pandas==1.1.5,pyarrow==0.14.1,s3fs')\n",
      "('spark.hadoop.yarn.timeline-service.enabled', 'false')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.decommissioning.timeout.threshold', '20')\n",
      "('spark.sql.catalogImplementation', 'hive')\n",
      "('spark.stage.attempt.ignoreOnDecommissionFetchFailure', 'true')\n",
      "('spark.pyspark.virtualenv.enabled', 'true')\n",
      "('spark.livy.spark_major_version', '2')\n",
      "('spark.ui.proxyBase', '/proxy/application_1666113837887_0001')\n",
      "('spark.executor.extraLibraryPath', '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native')\n",
      "('spark.dynamicAllocation.executorIdleTimeout', '18000')\n",
      "('spark.sql.files.ignoreCorruptFiles', 'true')\n",
      "('spark.pyspark.virtualenv.bin.path', '/usr/bin/virtualenv')\n",
      "('spark.hadoop.fs.s3.getObject.initialSocketTimeoutMilliseconds', '2000')\n",
      "('spark.driver.port', '33571')\n",
      "('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version.emr_internal_use_only.EmrFileSystem', '2')\n",
      "('spark.driver.host', 'ip-172-31-2-48.us-east-2.compute.internal')\n",
      "('spark.driver.appUIAddress', 'http://ip-172-31-2-48.us-east-2.compute.internal:4040')\n",
      "('spark.yarn.submit.waitAppCompletion', 'false')\n",
      "('spark.pyspark.virtualenv.type', 'native')\n",
      "('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS', 'ip-172-31-2-48.us-east-2.compute.internal')\n",
      "('spark.yarn.dist.pyFiles', 'file:///usr/lib/spark/python/lib/pyspark.zip,file:///usr/lib/spark/python/lib/py4j-0.10.7-src.zip')\n",
      "('spark.executor.cores', '4')\n",
      "('spark.yarn.dist.archives', 'file:/usr/lib/spark/R/lib/sparkr.zip#sparkr')\n",
      "('spark.app.id', 'application_1666113837887_0001')\n",
      "('spark.yarn.maxAppAttempts', '1')\n",
      "('spark.executor.defaultJavaOptions', \"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseParallelGC -XX:InitiatingHeapOccupancyPercent=70\")\n",
      "('spark.sql.hive.metastore.sharedPrefixes', 'com.amazonaws.services.dynamodbv2')\n",
      "('spark.yarn.dist.jars', 'file:///usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:///usr/lib/livy/repl_2.11-jars/commons-codec-1.9.jar,file:///usr/lib/livy/repl_2.11-jars/livy-core_2.11-0.7.0-incubating.jar,file:///usr/lib/livy/repl_2.11-jars/livy-repl_2.11-0.7.0-incubating.jar')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.sql.parquet.fs.optimized.committer.optimization-enabled', 'true')\n",
      "('spark.driver.extraClassPath', '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar')\n",
      "('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES', 'http://ip-172-31-2-48.us-east-2.compute.internal:20888/proxy/application_1666113837887_0001')\n",
      "('spark.hadoop.mapreduce.fileoutputcommitter.cleanup-failures.ignored.emr_internal_use_only.EmrFileSystem', 'true')\n",
      "('spark.repl.class.uri', 'spark://ip-172-31-2-48.us-east-2.compute.internal:33571/classes')\n",
      "('spark.yarn.tags', 'livy-session-0-eoKD2k9A')\n",
      "('spark.history.ui.port', '18080')\n",
      "('spark.shuffle.service.enabled', 'true')\n",
      "('spark.repl.local.jars', 'file:///usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:///usr/lib/livy/repl_2.11-jars/commons-codec-1.9.jar,file:///usr/lib/livy/repl_2.11-jars/livy-core_2.11-0.7.0-incubating.jar,file:///usr/lib/livy/repl_2.11-jars/livy-repl_2.11-0.7.0-incubating.jar')\n",
      "('spark.resourceManager.cleanupExpiredHost', 'true')\n",
      "('spark.executor.extraClassPath', '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar')\n",
      "('spark.yarn.dist.files', 'file:/etc/spark/conf/hive-site.xml')\n",
      "('spark.app.name', 'livy-session-0')\n",
      "('spark.files.fetchFailure.unRegisterOutputOnHost', 'true')\n",
      "('spark.driver.maxResultSize', '5g')\n",
      "('spark.driver.defaultJavaOptions', \"-XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled\")\n",
      "('spark.master', 'yarn')\n",
      "('spark.yarn.historyServer.address', 'ip-172-31-2-48.us-east-2.compute.internal:18080')\n",
      "('spark.submit.pyFiles', '/usr/lib/spark/python/lib/pyspark.zip,/usr/lib/spark/python/lib/py4j-0.10.7-src.zip')\n",
      "('spark.yarn.isPython', 'true')\n",
      "('spark.dynamicAllocation.enabled', 'true')\n",
      "('spark.blacklist.decommissioning.enabled', 'true')"
     ]
    }
   ],
   "source": [
    "print(spark.version,\"\\n\\n\")\n",
    "configurations = spark.sparkContext.getConf().getAll()\n",
    "for conf in configurations:\n",
    "    print(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T17:46:46.905866Z",
     "iopub.status.busy": "2022-10-18T17:46:46.905538Z",
     "iopub.status.idle": "2022-10-18T17:47:24.854969Z",
     "shell.execute_reply": "2022-10-18T17:47:24.854068Z",
     "shell.execute_reply.started": "2022-10-18T17:46:46.905836Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b3fd2b09f74c7c8e3a9a76b4282426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+----------------------------------+------------------------+------------------------+-----------------------+--------------------------------+--------------------------------+------------------------+-------+\n",
      "|Feed_mt_roundlot_bbo|f_mt_roundlot_bbo|exchange_timestamp_mt_roundlot_bbo|best_bid_mt_roundlot_bbo|best_ask_mt_roundlot_bbo|bid_ask_mt_roundlot_bbo|timestamp_ts_utc_mt_roundlot_bbo|timestamp_ts_est_mt_roundlot_bbo|FeedType_mt_roundlot_bbo|Product|\n",
      "+--------------------+-----------------+----------------------------------+------------------------+------------------------+-----------------------+--------------------------------+--------------------------------+------------------------+-------+\n",
      "|                 CQS|       cqs_pillar|               1654070400014248704|                  52.690|                  52.950|               0.004935|             2022-06-01 08:00:00|             2022-06-01 04:00:00|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182599544659200|                  53.470|                  53.530|               0.001122|             2022-06-02 15:09:59|             2022-06-02 11:09:59|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654070526527819776|                  52.630|                  52.830|               0.003800|             2022-06-01 08:02:06|             2022-06-01 04:02:06|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182600185411000|                  53.390|                  53.620|               0.004308|             2022-06-02 15:10:00|             2022-06-02 11:10:00|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654070755814249000|                  51.930|                  52.910|               0.018872|             2022-06-01 08:05:55|             2022-06-01 04:05:55|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182604057767711|                  53.470|                  53.580|               0.002057|             2022-06-02 15:10:04|             2022-06-02 11:10:04|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654071928814661120|                  52.450|                  52.550|               0.001907|             2022-06-01 08:25:28|             2022-06-01 04:25:28|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182604311132000|                  53.470|                  53.530|               0.001122|             2022-06-02 15:10:04|             2022-06-02 11:10:04|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654071933668205741|                  52.420|                  52.550|               0.002480|             2022-06-01 08:25:33|             2022-06-01 04:25:33|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182616286229000|                  53.470|                  53.550|               0.001496|             2022-06-02 15:10:16|             2022-06-02 11:10:16|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654072080873222000|                  52.380|                  52.540|               0.003055|             2022-06-01 08:28:00|             2022-06-01 04:28:00|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182619062683648|                  53.470|                  53.590|               0.002244|             2022-06-02 15:10:19|             2022-06-02 11:10:19|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654072387046543104|                  52.590|                  52.680|               0.001711|             2022-06-01 08:33:07|             2022-06-01 04:33:07|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182620836671000|                  53.510|                  53.620|               0.002056|             2022-06-02 15:10:20|             2022-06-02 11:10:20|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654072651033404928|                  52.570|                  52.650|               0.001522|             2022-06-01 08:37:31|             2022-06-01 04:37:31|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182629664823684|                  53.520|                  53.570|               0.000934|             2022-06-02 15:10:29|             2022-06-02 11:10:29|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654074354420452352|                  52.640|                  52.720|               0.001520|             2022-06-01 09:05:54|             2022-06-01 05:05:54|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182633627110656|                  53.540|                  64.760|               0.209563|             2022-06-02 15:10:33|             2022-06-02 11:10:33|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654074471282137600|                  52.730|                  52.830|               0.001896|             2022-06-01 09:07:51|             2022-06-01 05:07:51|            mt=bbo_quote|   URTY|\n",
      "|                 CQS|       cqs_pillar|               1654182650465088192|                  53.620|                  53.670|               0.000932|             2022-06-02 15:10:50|             2022-06-02 11:10:50|            mt=bbo_quote|   URTY|\n",
      "+--------------------+-----------------+----------------------------------+------------------------+------------------------+-----------------------+--------------------------------+--------------------------------+------------------------+-------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "one_file=\"s3://maystreetdata/feeds_norm/partition_scheme_experiments_7/mstnorm_parquet_0_5_0/mt_roundlot_bbo.parquet/\"\n",
    "d_df=spark.read.parquet(one_file)\n",
    "d_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T13:51:38.214430Z",
     "iopub.status.busy": "2022-10-11T13:51:38.214088Z",
     "iopub.status.idle": "2022-10-11T13:52:11.317704Z",
     "shell.execute_reply": "2022-10-11T13:52:11.316624Z",
     "shell.execute_reply.started": "2022-10-11T13:51:38.214401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f970dbd5f54726af6354a211964dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_array=['f=bats_edga',\n",
    "'f=bats_edgx',\n",
    "'f=byx',\n",
    "'f=bzx',\n",
    "'f=cts_pillar',\n",
    "'f=iex_deep',\n",
    "'f=memoir_depth',\n",
    "'f=miax_pearl_equities_dom',\n",
    "'f=total_view_bx',\n",
    "'f=total_view_psx',\n",
    "'f=total_view',\n",
    "'f=utdf_binary',\n",
    "'f=xdp_american_integrated',\n",
    "'f=xdp_arca_integrated',\n",
    "'f=xdp_chicago_integrated',\n",
    "'f=xdp_national_integrated',\n",
    "'f=xdp_nyse_integrated',]\n",
    "root_dir = 's3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0/mt=trade/'\n",
    "may_street_rootdir='s3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0'\n",
    "may_street_feeds=[\n",
    "'mt=add_order',\n",
    "'mt=aggregated_price_update',\n",
    "'mt=auction_summary',\n",
    "'mt=bbo_quote',\n",
    "'mt=cancel_order',\n",
    "'mt=clear_orders',\n",
    "'mt=feed_status',\n",
    "'mt=index_update',\n",
    "'mt=market_status',\n",
    "'mt=missing_packets',\n",
    "'mt=modify_order',\n",
    "'mt=nbbo_quote',\n",
    "'mt=order_imbalance',\n",
    "'mt=price_level_update',\n",
    "'mt=product_announcement',\n",
    "'mt=product_statistics',\n",
    "'mt=product_status',\n",
    "'mt=retail_price_improvement',\n",
    "'mt=trade_break',\n",
    "'mt=trade_correction',\n",
    "'mt=trade',]\n",
    "f_array=['f=bats_edga/',\n",
    "'f=bats_edgx/',\n",
    "'f=byx/',\n",
    "'f=bzx/',\n",
    "'f=iex_deep/',\n",
    "'f=memoir_depth/',\n",
    "'f=miax_pearl_equities_dom/',\n",
    "'f=total_view_bx/',\n",
    "'f=total_view_psx/',\n",
    "'f=total_view/',\n",
    "'f=xdp_american_integrated/',\n",
    "'f=xdp_arca_integrated/',\n",
    "'f=xdp_chicago_integrated/',\n",
    "'f=xdp_national_integrated/',\n",
    "'f=xdp_nyse_integrated/',]\n",
    "def get_data(root_dir,sub_dir_array):\n",
    "    all_dfs={}\n",
    "    data_df=None\n",
    "    for one_feed in sub_dir_array:\n",
    "        one_file = f'{root_dir}/{one_feed}/'\n",
    "        try:\n",
    "            one_df = spark.read.parquet(one_file)\n",
    "            all_dfs[one_feed]=one_df\n",
    "            if data_df is None:\n",
    "                data_df=one_df\n",
    "            else:\n",
    "                data_df=data_df.union(one_df)\n",
    "        except Exception as l_exc:\n",
    "             all_dfs[one_feed]=f'exc:{l_exc}'\n",
    "    return(all_dfs,data_df)\n",
    "trade_df_array,trade_df=get_data('s3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0/mt=aggregated_price_update/',f_array)\n",
    "#nbbo_df_array,nbbo_df=get_data('s3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0/mt=aggregated_price_update',[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-18T16:31:52.929250Z",
     "iopub.status.idle": "2022-10-18T16:31:52.931710Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_df = spark.read.parquet('s3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0/mt=aggregated_price_update/f=bats_edgx/')\n",
    "one_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T13:52:14.729030Z",
     "iopub.status.busy": "2022-10-11T13:52:14.720986Z",
     "iopub.status.idle": "2022-10-11T14:05:13.293596Z",
     "shell.execute_reply": "2022-10-11T14:05:13.289861Z",
     "shell.execute_reply.started": "2022-10-11T13:52:14.728971Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a06a946d9d14e6891c085d3a63f393b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|         Feed|      count|\n",
      "+-------------+-----------+\n",
      "|    BatsPitch|14862165929|\n",
      "|       MEMOIR| 4599698360|\n",
      "|        XDPV2|14991765142|\n",
      "|          IEX| 2116669098|\n",
      "| MIAXEquities| 1237173174|\n",
      "|TotalViewItch|12610378274|\n",
      "+-------------+-----------+"
     ]
    }
   ],
   "source": [
    "trade_df.groupby('Feed').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T14:30:02.603108Z",
     "iopub.status.busy": "2022-10-11T14:30:02.602703Z",
     "iopub.status.idle": "2022-10-11T14:32:44.437168Z",
     "shell.execute_reply": "2022-10-11T14:32:44.435435Z",
     "shell.execute_reply.started": "2022-10-11T14:30:02.603075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f9c03ddde6493d966e72dae9c818c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f=bats_edga/': 1930735935, 'f=bats_edgx/': 5150372274, 'f=byx/': 1368287073, 'f=bzx/': 6412770647, 'f=iex_deep/': 2116669098, 'f=memoir_depth/': 4599698360, 'f=miax_pearl_equities_dom/': 1237173174, 'f=total_view_bx/': 1015498285, 'f=total_view_psx/': 1730156613, 'f=total_view/': 9864723376, 'f=xdp_american_integrated/': 1363483825, 'f=xdp_arca_integrated/': 7360890672, 'f=xdp_chicago_integrated/': 727316432, 'f=xdp_national_integrated/': 562030990, 'f=xdp_nyse_integrated/': 4978043223}"
     ]
    }
   ],
   "source": [
    "res_dict={}\n",
    "for k,v in trade_df_array.items():\n",
    "    res_dict[k] = (v.count())\n",
    "    \n",
    "res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T00:22:38.626929Z",
     "iopub.status.busy": "2022-10-11T00:22:38.626589Z",
     "iopub.status.idle": "2022-10-11T00:22:40.324208Z",
     "shell.execute_reply": "2022-10-11T00:22:40.322879Z",
     "shell.execute_reply.started": "2022-10-11T00:22:38.626896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba0c6959ff24fc5bc2cd29c874e07eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27802"
     ]
    }
   ],
   "source": [
    "trade_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T00:23:01.488609Z",
     "iopub.status.busy": "2022-10-11T00:23:01.488253Z",
     "iopub.status.idle": "2022-10-11T00:57:23.697229Z",
     "shell.execute_reply": "2022-10-11T00:57:23.696081Z",
     "shell.execute_reply.started": "2022-10-11T00:23:01.488577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe595d1f61347bbabde3af92f864b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while calling o450.parquet.\n",
      ": org.apache.spark.SparkException: Job aborted.\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:173)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:173)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:197)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:194)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:114)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:112)\n",
      "\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:677)\n",
      "\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:677)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$executeQuery$1(SQLExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1$$anonfun$apply$1.apply(SQLExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecutionMetrics$.withMetrics(QueryExecutionMetrics.scala:141)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$withMetrics(SQLExecution.scala:178)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:200)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:92)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:677)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:286)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:272)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:230)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:567)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Job 23 cancelled because SparkContext was shut down\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:973)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:971)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:971)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2288)\n",
      "\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2195)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1385)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1948)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:121)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.checkNoFailures(AdaptiveExecutor.scala:146)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.doRun(AdaptiveExecutor.scala:88)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.tryRunningAndGetFuture(AdaptiveExecutor.scala:66)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.execute(AdaptiveExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:128)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:127)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:778)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.finalPhysicalPlan(AdaptiveSparkPlanExec.scala:127)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.doExecute(AdaptiveSparkPlanExec.scala:132)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:173)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:197)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:194)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SortExec.doExecute(SortExec.scala:122)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:173)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:197)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:194)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:154)\n",
      "\t... 37 more\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 844, in parquet\n",
      "    self._jwrite.parquet(path)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o450.parquet.\n",
      ": org.apache.spark.SparkException: Job aborted.\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:173)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:173)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:197)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:194)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:114)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:112)\n",
      "\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:677)\n",
      "\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:677)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$executeQuery$1(SQLExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1$$anonfun$apply$1.apply(SQLExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecutionMetrics$.withMetrics(QueryExecutionMetrics.scala:141)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$withMetrics(SQLExecution.scala:178)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:200)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:92)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:677)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:286)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:272)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:230)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:567)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Job 23 cancelled because SparkContext was shut down\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:973)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:971)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:971)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2288)\n",
      "\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2195)\n",
      "\tat org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1385)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:1948)\n",
      "\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend$MonitorThread.run(YarnClientSchedulerBackend.scala:121)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.checkNoFailures(AdaptiveExecutor.scala:146)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.doRun(AdaptiveExecutor.scala:88)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.tryRunningAndGetFuture(AdaptiveExecutor.scala:66)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.execute(AdaptiveExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:128)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:127)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:778)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.finalPhysicalPlan(AdaptiveSparkPlanExec.scala:127)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.doExecute(AdaptiveSparkPlanExec.scala:132)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:173)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:197)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:194)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SortExec.doExecute(SortExec.scala:122)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:173)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:197)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:194)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:154)\n",
      "\t... 37 more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l_fname=f\"s3://maystreetdata/feeds_norm/partition_scheme_experiments_product_feed_dt/mstnorm_parquet_0_5_0/XDPV2_IEX_Total.parquet\"\n",
    "#trade_df.repartition(1).write\\\n",
    "trade_df.repartition(1000).write\\\n",
    "            .option(\"header\",True) \\\n",
    "            .partitionBy(\"Product\",\"Feed\",\"dt\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .parquet(f\"{l_fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T00:38:51.124251Z",
     "iopub.status.busy": "2022-09-28T00:38:51.123732Z",
     "iopub.status.idle": "2022-09-28T00:40:38.702245Z",
     "shell.execute_reply": "2022-09-28T00:40:38.701239Z",
     "shell.execute_reply.started": "2022-09-28T00:38:51.124210Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9dd95170674e0ea790639aa5e7e71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "                                                          #1636035828600286047\n",
    "trade_df.where(f\"Product=='{'SPY'}' and ExchangeTimestamp<{1661204000000431328}\")\\\n",
    ".orderBy('ExchangeTimestamp','SequenceNumber').toPandas().to_csv('s3://maystreetdata/analysis/spy_sample.csv')#.agg(py_f.min(py_f.col('ExchangeTimestamp')),py_f.max(py_f.col('ExchangeTimestamp'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T00:46:54.667219Z",
     "iopub.status.busy": "2022-09-28T00:46:54.666674Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e278894c9a44b598c0d712bc9f04c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b385182be9e64c47818e6e4f1a9842ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nbbo_df.where(f\"Product=='{'SPY'}' and LastExchangeTimestamp<{1661204000000431328}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T00:40:39.171112Z",
     "iopub.status.busy": "2022-09-28T00:40:39.170851Z",
     "iopub.status.idle": "2022-09-28T00:46:54.664825Z",
     "shell.execute_reply": "2022-09-28T00:46:54.663698Z",
     "shell.execute_reply.started": "2022-09-28T00:40:39.171085Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1434979fa6d4447fb5fb468b64c388c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spy_nbbo=nbbo_df.where(f\"Product=='{'SPY'}'\").select('Product','LastExchangeTimestamp','Feed', 'LastSequenceNumber', 'BidPrice_1','BidQuantity_1','AskPrice_1','AskQuantity_1')\\\n",
    ".withColumnRenamed('LastExchangeTimestamp','ExchangeTimestamp_nbbo').withColumnRenamed('Product','Product_nbbo').withColumnRenamed('LastSequenceNumber','SequenceNumber_nbbo')\n",
    "spy_trade=trade_df.where(f\"Product=='{'SPY'}'\")\n",
    "\n",
    "spy_nbbo_trade=spy_nbbo.join(spy_trade,(spy_nbbo.Product_nbbo==spy_trade.Product)  \n",
    "                             & (spy_nbbo.Feed==spy_trade.Feed) \n",
    "                             & (spy_nbbo.ExchangeTimestamp_nbbo==spy_trade.ExchangeTimestamp) ,'outer').drop(spy_trade.Feed)\n",
    "spy_nbbo_trade=spy_nbbo_trade.withColumn('exchange_ts',py_f.when(py_f.col(f'ExchangeTimestamp_nbbo').isNull(), py_f.col(f'ExchangeTimestamp')).otherwise(py_f.col(f'ExchangeTimestamp_nbbo')))\n",
    "spy_nbbo_trade.orderBy('exchange_ts','SequenceNumber_nbbo','SequenceNumber', 'ProductSequenceNumber')\\\n",
    ".select('Product_nbbo','SequenceNumber','Feed','SequenceNumber_nbbo', 'exchange_ts','Side', 'BidQuantity_1', 'BidPrice_1','Price','AskPrice_1', 'AskQuantity_1','Quantity','SaleCondition','SaleCondition2','SaleCondition3','SaleCondition4')\\\n",
    ".where(\"SaleCondition3 !='ExtendedHoursTrade' \").toPandas().to_csv('s3://maystreetdata/analysis/spy_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T17:49:31.339317Z",
     "iopub.status.busy": "2022-10-07T17:49:31.338990Z",
     "iopub.status.idle": "2022-10-07T17:49:31.602449Z",
     "shell.execute_reply": "2022-10-07T17:49:31.601450Z",
     "shell.execute_reply.started": "2022-10-07T17:49:31.339288Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5830f76f480a4fe6bb94032ca1bcca36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to open local file 's3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0/mt=aggregated_price_update/f=bats_edga/dt=2022-07-20/1.parquet', error: No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 11, in __init__\n",
      "  File \"/tmp/1665164519839-0/lib/python3.7/site-packages/pyarrow/parquet.py\", line 1423, in read_metadata\n",
      "    return ParquetFile(where, memory_map=memory_map).metadata\n",
      "  File \"/tmp/1665164519839-0/lib/python3.7/site-packages/pyarrow/parquet.py\", line 132, in __init__\n",
      "    self.reader.open(source, use_memory_map=memory_map, metadata=metadata)\n",
      "  File \"pyarrow/_parquet.pyx\", line 1002, in pyarrow._parquet.ParquetReader.open\n",
      "  File \"pyarrow/io.pxi\", line 1323, in pyarrow.lib.get_reader\n",
      "  File \"pyarrow/io.pxi\", line 1314, in pyarrow.lib._get_native_file\n",
      "  File \"pyarrow/io.pxi\", line 818, in pyarrow.lib.OSFile.__cinit__\n",
      "  File \"pyarrow/io.pxi\", line 828, in pyarrow.lib.OSFile._open_readable\n",
      "  File \"pyarrow/error.pxi\", line 87, in pyarrow.lib.check_status\n",
      "pyarrow.lib.ArrowIOError: Failed to open local file 's3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0/mt=aggregated_price_update/f=bats_edga/dt=2022-07-20/1.parquet', error: No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "class ParquetInspector(object):\n",
    "    \"\"\"docstring for ParquetInspector\"\"\"\n",
    "\n",
    "    def __init__(self, parquet_filepath):\n",
    "        super(ParquetInspector, self).__init__()\n",
    "        self.parquet_filepath = parquet_filepath\n",
    "\n",
    "        self.metadata = pq.read_metadata(self.parquet_filepath)\n",
    "\n",
    "    def footer_size(self):\n",
    "        return self.metadata_serialized_size()\n",
    "\n",
    "    def metadata_serialized_size(self):\n",
    "        return self.metadata.serialized_size\n",
    "\n",
    "    def row_count(self):\n",
    "        return self.metadata.num_rows\n",
    "\n",
    "parquet_path='s3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0/mt=aggregated_price_update/f=bats_edga/dt=2022-07-20/1.parquet'\n",
    "inspector = ParquetInspector(parquet_path)\n",
    "footer_size = inspector.footer_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
